{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTPsPHb_lWTE"
   },
   "source": [
    "### Apredizaje supervisado\n",
    "#### Autor: Rahimi Vilchez, Aiad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5W-65MskuXx"
   },
   "source": [
    "En este trabajo se aplicarán algunas técnicas aprendidas para el aprendizaje automático supervisado.\n",
    "\n",
    "Se utilizará un dataset de airbnb donde se buscará predecir el precio de las noches de cada hogar en función de algunas variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKUpHSLqkuXz"
   },
   "source": [
    "#### Variables:\n",
    "- Unnamed: 0: Variable de contador de registros (no será utilizada en nuetro análisis)\n",
    "- neighbourhood: Barrio donde se encuentra ubicado la casa.\n",
    "- room_type: Tipo de hogar en alquiler.\n",
    "- price: Precio por noche.\n",
    "- minimum_nights: Cantidad minimas de noches que pueden alquilar el hogar.\n",
    "- number_of_reviews: Cantidad de reviews\n",
    "- reviews_per_month: Tasa de reviews que tienen por mes\n",
    "- calculated_host_listings_count: Cantidad de hogares ofrecidos por el host.\n",
    "- availability_365: Cantidad de dias que se encuentra en alquiler el hogar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWk9Vqs8l5jg"
   },
   "source": [
    "### Objetivos principales:\n",
    "- resolver los requisitos que se detallan en las proximas celdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "7VzMW3fvkuX0"
   },
   "outputs": [],
   "source": [
    "## Importo librerías de maniupulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "NFgDAUVLNfhE"
   },
   "outputs": [],
   "source": [
    "# Importo librerías de Aprendizaje automático\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7h4SOeAkuX4"
   },
   "source": [
    "##### **Objetivo 1**\n",
    "Lo primero que deberan hacer será importar\n",
    "- el dataset bajo en nombre \"london\"\n",
    "- corroborar que lo hayamos cargado correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "2EOIgMedmgBM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51817</th>\n",
       "      <td>74704</td>\n",
       "      <td>Tower Hamlets</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51818</th>\n",
       "      <td>74729</td>\n",
       "      <td>Lambeth</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51819</th>\n",
       "      <td>74741</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51820</th>\n",
       "      <td>74754</td>\n",
       "      <td>Hammersmith and Fulham</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51821</th>\n",
       "      <td>74785</td>\n",
       "      <td>Brent</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51822</th>\n",
       "      <td>74816</td>\n",
       "      <td>Brent</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51823</th>\n",
       "      <td>74927</td>\n",
       "      <td>Lewisham</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51824</th>\n",
       "      <td>75003</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>280</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51825</th>\n",
       "      <td>75054</td>\n",
       "      <td>Tower Hamlets</td>\n",
       "      <td>Private room</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51826</th>\n",
       "      <td>75192</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>Private room</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0           neighbourhood        room_type  price  \\\n",
       "51817       74704           Tower Hamlets  Entire home/apt     90   \n",
       "51818       74729                 Lambeth  Entire home/apt    188   \n",
       "51819       74741             Westminster  Entire home/apt     60   \n",
       "51820       74754  Hammersmith and Fulham  Entire home/apt    120   \n",
       "51821       74785                   Brent  Entire home/apt    150   \n",
       "51822       74816                   Brent  Entire home/apt     60   \n",
       "51823       74927                Lewisham  Entire home/apt     30   \n",
       "51824       75003             Westminster  Entire home/apt    280   \n",
       "51825       75054           Tower Hamlets     Private room     35   \n",
       "51826       75192             Westminster     Private room     66   \n",
       "\n",
       "       minimum_nights  number_of_reviews  reviews_per_month  \\\n",
       "51817               3                  1                1.0   \n",
       "51818               2                  1                1.0   \n",
       "51819               1                  1                1.0   \n",
       "51820               3                  1                1.0   \n",
       "51821               1                  1                1.0   \n",
       "51822               5                  1                1.0   \n",
       "51823               2                  1                1.0   \n",
       "51824               3                  1                1.0   \n",
       "51825               2                  1                1.0   \n",
       "51826               2                  1                1.0   \n",
       "\n",
       "       calculated_host_listings_count  availability_365  \n",
       "51817                               1               195  \n",
       "51818                               1               294  \n",
       "51819                               1                82  \n",
       "51820                               1                26  \n",
       "51821                               8               327  \n",
       "51822                               1                 7  \n",
       "51823                               1                26  \n",
       "51824                              14               352  \n",
       "51825                               1                13  \n",
       "51826                               1               140  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargo london y corroboro\n",
    "london = pd.read_csv('TP2_airbnb_london.csv')\n",
    "london.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFZY1u8XkuX5"
   },
   "source": [
    "##### **Objetivo 2**\n",
    "Ahora imprimir también las dimensiones del dataset y eliminar la variable \"Unnamed:0\" del dataset.\n",
    "Volver a guardar el dataset sin esta variable bajo el nombre \"london\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "V6WzWe1JkuX7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las dimensiones del dataset london son (51827, 9)\n"
     ]
    }
   ],
   "source": [
    "# Imprimo dimensiones\n",
    "dimensiones = london.shape\n",
    "print(f\"Las dimensiones del dataset london son {dimensiones}\")\n",
    "london = london.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6rbeiRvkuX8"
   },
   "source": [
    "##### **Objetivo 3**\n",
    "Corroborar que el dataset no cuenta con valores nulos, si los hubiera llenarlos todos con 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "huJVDzyTkuX8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hay Nans en el dataset\n"
     ]
    }
   ],
   "source": [
    "# Verifico la existencia de Nans\n",
    "total_nans = london.isnull().sum().sort_values(ascending=False)\n",
    "if list(total_nans) != 0:\n",
    "    print(\"No hay Nans en el dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5K3hnLhkuX9"
   },
   "source": [
    "##### **Objetivo 4**\n",
    "Mostrar el tipo de dato para las variables \"neighbourhood\" y \"room_type\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "buyjxSDNkuX-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de dato para la variable neighbourhood: object\n",
      "Tipo de dato para la variable room_type: object\n",
      "object significa “objeto”, que en el mundo de Pandas es una secuencia de caracteres (texto)\n"
     ]
    }
   ],
   "source": [
    "# Muestro el tipo de dato para cada variable\n",
    "neighbourhood_dtype = london[\"neighbourhood\"].dtype\n",
    "room_type_dtype = london[\"room_type\"].dtype\n",
    "print(f\"Tipo de dato para la variable neighbourhood: {neighbourhood_dtype}\")\n",
    "print(f\"Tipo de dato para la variable room_type: {room_type_dtype}\")\n",
    "print(f\"{neighbourhood_dtype} significa “objeto”, que en el mundo de Pandas es una secuencia de caracteres (texto)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Pif7gnqkuX-"
   },
   "source": [
    "##### **Objetivo 5**\n",
    "Generar las variables dummies para estas dos variables categóricas y unirlas al dataset london.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "WQ2GszPKNfhI"
   },
   "outputs": [],
   "source": [
    "# Creo una lista de cada variable para generar luego sus dummies\n",
    "neigh_list = list(london[\"neighbourhood\"])\n",
    "room_list = list(london[\"room_type\"])\n",
    "# Genero las dummies para la variable neighbourhood, dentro de la variable neigh_dummies.\n",
    "le1 = preprocessing.LabelEncoder()\n",
    "neigh_dummies = le1.fit_transform(neigh_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9raTKcGNfhJ"
   },
   "source": [
    "Imprimir las dimensiones y primeras lineas de estas dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "x5aYhwWcNfhJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> con 51827 filas y 0 columnas\n"
     ]
    }
   ],
   "source": [
    "# Imprimo el tipo y las dimesiones\n",
    "print(f\"{type(neigh_dummies)} con {np.shape(neigh_dummies)[0]} filas y 0 columnas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "ehoVgr9NNfhJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13,  8, 18, 29,  1, 18, 18, 29,  1, 27], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primeras líneas\n",
    "neigh_dummies[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "qdGPJ4tONfhJ"
   },
   "outputs": [],
   "source": [
    "# Genero las dummies para la variable room_type, dentro de la variable room_dummies.\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "room_dummies = le2.fit_transform(room_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDHhvq4_NfhJ"
   },
   "source": [
    "Imprimir las dimensiones y primeras lineas de estas dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "ssP3nFUcNfhJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> con 51827 filas y 0 columnas\n"
     ]
    }
   ],
   "source": [
    "# Imprimo el tipo y las dimesiones\n",
    "print(f\"{type(room_dummies)} con {np.shape(room_dummies)[0]} filas y 0 columnas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "jmB-t-3hNfhK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 0, 0, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primeras líneas\n",
    "room_dummies[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8CG_MEdkuX-"
   },
   "source": [
    "Joinear las variables dummies al dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "3Q0w7z_uNfhK"
   },
   "outputs": [],
   "source": [
    "# Creo los DataFrame a partir de los np.arrays para poder concatenarlos con .concat()\n",
    "neigh_dummies_df = pd.DataFrame([neigh_dummies]).T\n",
    "room_dummies_df = pd.DataFrame([room_dummies]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambio el nombre de la columna \"0\" por neigh_dummies y room_dummies respectivamente en cada DataFrame\n",
    "neigh_dummies_df = neigh_dummies_df.rename({0 : \"neigh_dummies\"}, axis = 1)\n",
    "room_dummies_df = room_dummies_df.rename({0 : \"room_dummies\"}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concateno las dos variables dummies al dataset principal\n",
    "london = pd.concat([london,neigh_dummies_df,room_dummies_df], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjPPQtG6kuX_"
   },
   "source": [
    "##### Dividiremos nuestro dataset en la variable dependiente \"y\" (label o etiqueta) y las variables independientes \"x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "1TZWtiVTkuX_"
   },
   "outputs": [],
   "source": [
    "# La variable dependiente es el precio, miestras que las independeientes son las otras\n",
    "# Eliminamos también 'neighbourhood' y 'room_type' porque ya joinié sus dummies\n",
    "y = np.array(london[[\"price\"]])\n",
    "x = london.drop(['price', 'neighbourhood', 'room_type'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-2ujF5MkuYA"
   },
   "source": [
    "##### **Objetivo 7**\n",
    "\n",
    "Dividir el dataset entre Train y Test, tomar un test_size del 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "SBepVVKIkuYA"
   },
   "outputs": [],
   "source": [
    "# Separo train y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfDnVu6hkuYB"
   },
   "source": [
    "##### **Objetivo 8**\n",
    "Con el StandardScaler generado en la linea siguiente, realizar el transform para el xtrain y xtest guardandolos en nuevas variables llamadas \"xtrain_scal\" y \"xtest_scal\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "QgDYMr1qNfhL"
   },
   "outputs": [],
   "source": [
    "# Estandarización de x_train\n",
    "scaler1 = preprocessing.StandardScaler().fit(x_train)\n",
    "xtrain_scal = scaler1.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "PTdTOdUANfhL"
   },
   "outputs": [],
   "source": [
    "# Estandarización de x_test\n",
    "scaler2 = preprocessing.StandardScaler().fit(x_test)\n",
    "xtest_scal = scaler2.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hkXK5_ckuYC"
   },
   "source": [
    "##### **Objetivo 9**\n",
    "Crear un modelo lineal y entrenarlo para nuestro dataset.\n",
    "\n",
    "Obtener las predicciones y el \"mean_squared_error\" para el test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "60x_-aowNfhM"
   },
   "outputs": [],
   "source": [
    "# Entrenamos el modelo\n",
    "reg = LinearRegression().fit(xtrain_scal, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "CNBZVUxjNfhM"
   },
   "outputs": [],
   "source": [
    "# Predigo un array y_pred con valores aprendidos por el modelo mediante x_test\n",
    "y_pred = reg.predict(xtest_scal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "P8am8EVokuYD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1753.243976575432"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculo MSE\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQpkINPIkuYD"
   },
   "source": [
    "##### **Objetivo 10**\n",
    "Crear un SVM Regressor y un GridSearch para realizar la búsqueda de hiperparámetros.\n",
    "\n",
    "Asignar dos posibles valores para el parámetro \"kernel\", y tres posibles valores para \"C\" y \"gamma\".\n",
    "\n",
    "Setear al parámetro \"refit\" en True y hacer 5 CrossValidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyh2r-iJNfhM"
   },
   "outputs": [],
   "source": [
    "# Entreno el modelo\n",
    "svreg = SVR()\n",
    "param_svreg = {'kernel':('linear', 'rbf'), 'C':[0.1, 1, 10 ], 'gamma':[0.01, 0.1, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JK2ZKv6ONfhM"
   },
   "outputs": [],
   "source": [
    "regressor_svr = GridSearchCV(svreg, param_svreg, cv = 5, refit = True, verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7CD4cIYUkuYE"
   },
   "outputs": [],
   "source": [
    "regressor_svr.fit(xtrain_scal, y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOuBv_mfkuYG"
   },
   "source": [
    "##### **Objetivo 11**\n",
    "\n",
    "Mostrar cuales fueron los mejores hiperparámetros y para estos obtener el mean_squared_error en el test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHwCIS0mNfhN"
   },
   "outputs": [],
   "source": [
    "# Mejores hiperparametros\n",
    "regressor_svr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vlMZBccQNfhN"
   },
   "outputs": [],
   "source": [
    "# Predigo un array y_pred2 con valores aprendidos por el modelo SVR mediante x_test\n",
    "y_pred2 = regressor_svr.predict(xtest_scal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fc8mozfEkuYH"
   },
   "outputs": [],
   "source": [
    "# Calculo el MSE\n",
    "mse1 = mean_squared_error(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJQSlAT_kuYH"
   },
   "source": [
    "##### **Objetivo 12**\n",
    "Repetir el objetivo 10 pero ahora seteando nuevos valores para los hiperparámetros mencionados con el objetivo de mejorar las predicciones.\n",
    "\n",
    "Cuales son los mejores hiperparámetros ahora?\n",
    "Obtenemos una mejora en las predicciones?\n",
    "Mostrar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LmYGwWhokuYI"
   },
   "outputs": [],
   "source": [
    "# Entreno el modelo\n",
    "svreg1 = SVR()\n",
    "param_svreg1 = {'kernel':('linear', 'rbf'), 'C':[0.01, 100, 1000 ], 'gamma':[ 0.0001, 0.001, 10]}\n",
    "regressor_svr1 = GridSearchCV(svreg1, param_svreg, cv = 5, refit = True, verbose = 3)\n",
    "regressor_svr1.fit(xtrain_scal, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WyMHn-XYn5Uv"
   },
   "outputs": [],
   "source": [
    "# Mejores hipermparametros\n",
    "regressor_svr1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GyUOMDd7kuYI"
   },
   "outputs": [],
   "source": [
    "# Predigo un array y_pred3 con valores aprendidos por el modelo SVR mediante x_test\n",
    "y_pred3 = regressor_svr1.predict(xtest_scal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJ0-nJNHkuYJ"
   },
   "outputs": [],
   "source": [
    "# Calculo el MSE\n",
    "mse2 = mean_squared_error(y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrasto los dos MSE obtenidos para comparar el desempeño de los dos modelos\n",
    "if mse1 > mse2:\n",
    "    print(\"No se obtuvo una mejora en las predicciones\")\n",
    "else:\n",
    "    print(\"Se obtuvo una mejora en las predicciones\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "c63d8c7d738c2960218a10995aedf0a7f67a49a231e71037adf0440953cdb45b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
